# Databricks notebook source
# MAGIC %load_ext autoreload
# MAGIC %autoreload 2
# MAGIC # Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules
# MAGIC # To disable autoreload; run %autoreload 0

# COMMAND ----------

# DBTITLE 1,Model Serving Pipeline - Overview
##################################################################################
# Model Serving
#
# Helper notebook to serve the model on an endpoint. This notebook is run
# after the ModelDeployment.py notebook as part of a multi-task job, in order to serve the model
# on an endpoint stage after transitioning the latest version.
#
# Parameters:
# * uc_catalog (required)                   - Name of the Unity Catalog
# * schema (required)                       - Name of the schema inside Unity Catalog
# * registered_model (required)             - Name of the model registered in mlflow
# * model_alias (required)                  - Model alias to deploy
# * scale_to_zero (required)                - Specify if the endpoint should scale to zero when not in use.
# * workload_size (required)                - Specify  the size of the compute scale out that corresponds with the number of requests this served
#                                             model can process at the same time. This number should be roughly equal to QPS x model run time.
# * agent_serving_endpoint (required)       - Name of the agent serving endpoint to deploy
# * mlflow_experiment_path (optional)       - Non-Git MLflow experiment path for tracing
# * deploy_max_attempts (optional)          - Maximum deployment retry attempts (default: 3)
# * deploy_base_sleep_sec (optional)        - Base sleep time for retry backoff (default: 10)
#
# Widgets:
# * Unity Catalog: Text widget to input the name of the Unity Catalog
# * Schema: Text widget to input the name of the database inside the Unity Catalog
# * Registered model name: Text widget to input the name of the model to register in mlflow
# * Model Alias: Text widget to input the model alias to deploy
# * Scale to zero: Whether the clusters should scale to zero (requiring more time at startup after inactivity)
# * Workload Size: Compute that matches estimated number of requests for the endpoint
# * Agent model serving endpoint: Text widget to input the name of the model serving endpoint to deploy
#
# Usage:
# 1. Set the appropriate values for the widgets.
# 2. Add members that you want to grant access to for the review app to the user_list.
# 3. Run to deploy endpoint.
#
##################################################################################

# COMMAND ----------

# DBTITLE 1,Install Prerequisites
# Install prerequisite packages
%pip install -r ../../../agent_development/agent_requirements.txt

# COMMAND ----------

# DBTITLE 1,Widget Creation
# List of input args needed to run the notebook as a job.
# Provide them via DB widgets or notebook arguments.

# A Unity Catalog containing the model
dbutils.widgets.text(
    "uc_catalog",
    "",
    label="Unity Catalog",
)
# Name of schema
dbutils.widgets.text(
    "schema",
    "",
    label="Schema",
)
# Name of model registered in mlflow
dbutils.widgets.text(
    "registered_model",
    "agent_function_chatbot",
    label="Registered model name",
)
# Model alias
dbutils.widgets.text(
    "model_alias",
    "agent_latest",
    label="Model Alias",
)
# Scale to zero
dbutils.widgets.dropdown("scale_to_zero", "True", ["True", "False"], "Scale to zero")
# Workdload size
dbutils.widgets.dropdown("workload_size", "Small", ["Small", "Medium", "Large"], "Workload Size")
# Agent serving endpoint (optional - leave empty to auto-generate)
# Per Databricks guidance: agents.deploy() can create the endpoint with a custom name,
# but the endpoint must NOT be pre-created in DAB/Terraform
# Pass a name for cleaner endpoint management, or leave empty to auto-generate
dbutils.widgets.text(
    "agent_serving_endpoint",
    "chatbot_model_serving_endpoint",
    label="Agent serving endpoint (optional)",
)
# MLflow experiment path (optional)
dbutils.widgets.text(
    "mlflow_experiment_path",
    "",
    label="MLflow Experiment Path (optional)",
)
# Deployment retry settings
dbutils.widgets.text(
    "deploy_max_attempts",
    "3",
    label="Max deployment attempts",
)
dbutils.widgets.text(
    "deploy_base_sleep_sec",
    "10",
    label="Base sleep seconds for retry",
)

# COMMAND ----------

# DBTITLE 1,Restart Python
dbutils.library.restartPython()

# COMMAND ----------

# DBTITLE 1,Define Input Variables
import time
from typing import Optional

def get_bool_param(value: str) -> bool:
    """Convert string widget value to boolean"""
    return str(value).lower() in ("1", "true", "yes", "y")

def get_int_param(value: str, default: int) -> int:
    """Convert string widget value to int with default"""
    try:
        return int(value)
    except (ValueError, TypeError):
        return default

def get_float_param(value: str, default: float) -> float:
    """Convert string widget value to float with default"""
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

uc_catalog = dbutils.widgets.get("uc_catalog")
schema = dbutils.widgets.get("schema")
registered_model = dbutils.widgets.get("registered_model")
model_alias = dbutils.widgets.get("model_alias")
scale_to_zero = get_bool_param(dbutils.widgets.get("scale_to_zero"))
workload_size = dbutils.widgets.get("workload_size")
agent_serving_endpoint = dbutils.widgets.get("agent_serving_endpoint")  # Optional - can be empty
mlflow_experiment_path = dbutils.widgets.get("mlflow_experiment_path")
deploy_max_attempts = get_int_param(dbutils.widgets.get("deploy_max_attempts"), 3)
deploy_base_sleep_sec = get_float_param(dbutils.widgets.get("deploy_base_sleep_sec"), 10.0)

assert uc_catalog != "", "uc_catalog notebook parameter must be specified"
assert schema != "", "schema notebook parameter must be specified"
assert registered_model != "", "registered_model notebook parameter must be specified"
assert model_alias != "", "model_alias notebook parameter must be specified"
# Note: agent_serving_endpoint is optional - if empty, agents.deploy() will auto-generate it

# COMMAND ----------

# DBTITLE 1,Configure MLflow for UC and Real-time Tracing
import mlflow
from databricks.sdk import WorkspaceClient

# Critical: Set UC registry and non-Git experiment before calling agents.deploy()
# This ensures MLflow 3 real-time tracing works in Git folders and bundle jobs
mlflow.set_registry_uri("databricks-uc")

# Use provided experiment path or create a default non-Git experiment
w = WorkspaceClient()
if not mlflow_experiment_path:
    mlflow_experiment_path = f"/Users/{w.current_user.me().user_name}/.agents-deploy-exp"

mlflow.set_experiment(mlflow_experiment_path)
print(f"Using MLflow experiment: {mlflow_experiment_path}")

# COMMAND ----------

# DBTITLE 1,Set up path to import utility functions
import sys
import os

# Get notebook's directory using dbutils
notebook_path = '/Workspace/' + os.path.dirname(
    dbutils.notebook.entry_point.getDbutils().notebook()
    .getContext().notebookPath().get()
)
# Navigate up from notebooks/ to component level
utils_dir = os.path.dirname(notebook_path)
sys.path.insert(0, utils_dir)

# COMMAND ----------
# DBTITLE 1,Review Instructions
instructions_to_reviewer = f"""### Instructions for Testing the our Chatbot assistant

Your inputs are invaluable for the development team. By providing detailed feedback and corrections, you help us fix issues and improve the overall quality of the application. We rely on your expertise to identify any gaps or areas needing enhancement.

1. **Variety of Questions**:
   - Please try a wide range of questions that you anticipate the end users of the application will ask. This helps us ensure the application can handle the expected queries effectively.

2. **Feedback on Answers**:
   - After asking each question, use the feedback widgets provided to review the answer given by the application.
   - If you think the answer is incorrect or could be improved, please use "Edit Answer" to correct it. Your corrections will enable our team to refine the application's accuracy.

3. **Review of Returned Documents**:
   - Carefully review each document that the system returns in response to your question.
   - Use the thumbs up/down feature to indicate whether the document was relevant to the question asked. A thumbs up signifies relevance, while a thumbs down indicates the document was not useful.

Thank you for your time and effort in testing our assistant. Your contributions are essential to delivering a high-quality product to our end users."""

# COMMAND ----------
# DBTITLE 1,Deploy Agent with Retry Logic

from databricks import agents
from mlflow import MlflowClient

client = MlflowClient()

model_name = f"{uc_catalog}.{schema}.{registered_model}"
model_version_obj = client.get_model_version_by_alias(model_name, model_alias)
model_version = int(model_version_obj.version)

print(f"Deploying model {model_name} version {model_version}")
print(f"Scale to zero: {scale_to_zero}, Workload size: {workload_size}")
if agent_serving_endpoint:
    print(f"Target endpoint name: {agent_serving_endpoint}")
else:
    print("No endpoint name specified - agents.deploy() will auto-generate one")

# Deploy with retry/backoff to handle intermittent failures
# This is critical because agents.deploy() can have transient issues during
# endpoint creation/update, especially when reading endpoint state
last_err = None
deployment = None

for attempt in range(1, deploy_max_attempts + 1):
    try:
        print(f"Deployment attempt {attempt}/{deploy_max_attempts}...")

        # CRITICAL: Let agents.deploy() own endpoint creation completely
        # - You CAN pass endpoint_name for cleaner naming (recommended)
        # - You must NOT pre-create the endpoint in DAB/Terraform
        # - If endpoint_name is empty/None, agents.deploy() will auto-generate it
        # See: https://docs.databricks.com/en/generative-ai/deploy-agent.html
        deployment = agents.deploy(
            model_name=model_name,
            model_version=model_version,
            endpoint_name=agent_serving_endpoint if agent_serving_endpoint else None,
            scale_to_zero_enabled=scale_to_zero,
        )

        print(f"Deployment initiated successfully!")
        print(f"Query endpoint: {deployment.query_endpoint}")
        last_err = None
        break

    except Exception as e:
        last_err = e
        error_msg = str(e)

        # Check for the known "served_entities" error
        if "served_entities" in error_msg.lower() or "nonetype" in error_msg.lower():
            print(f"Encountered known intermittent deployment issue: {error_msg}")
        else:
            print(f"Deployment error: {error_msg}")

        if attempt < deploy_max_attempts:
            sleep_for = deploy_base_sleep_sec * (2 ** (attempt - 1))
            print(f"Retrying in {sleep_for:.0f} seconds...")
            time.sleep(sleep_for)
        else:
            print(f"Deployment failed after {deploy_max_attempts} attempts")

if last_err:
    raise RuntimeError(
        f"Deployment failed after {deploy_max_attempts} attempts. "
        f"Last error: {last_err}"
    ) from last_err

# COMMAND ----------
# DBTITLE 1,Wait for Endpoint to be Ready

from utils import wait_for_model_serving_endpoint_to_be_ready

# Extract the endpoint name from the deployment object
# Since we didn't pass endpoint_name, agents.deploy() auto-generated it
endpoint_name = deployment.endpoint_name
print(f"Deployment created endpoint: {endpoint_name}")
print(f"Waiting for endpoint {endpoint_name} to be ready...")
wait_for_model_serving_endpoint_to_be_ready(endpoint_name)
print(f"Endpoint {endpoint_name} is ready!")

# COMMAND ----------
# DBTITLE 1,Set Review Instructions

agents.set_review_instructions(model_name, instructions_to_reviewer)
print("Review instructions set successfully")

# COMMAND ----------

# DBTITLE 1,Grant Permissions
#TODO grant your stakeholders permissions to use the Review App
# user_list = ["firstname.lastname@company.com"]

# Set the permissions.

# agents.set_permissions(model_name=model_name, users=user_list, permission_level=agents.PermissionLevel.CAN_QUERY)

# print(f"Share this URL with your stakeholders: {deployment.review_app_url}")

# COMMAND ----------
# DBTITLE 1,Test Endpoint

from mlflow.deployments import get_deploy_client

deploy_client = get_deploy_client()
input_example = {
    "input": [{"role": "user", "content": "What is MLflow?"}],
    "databricks_options": {"return_trace": True},
}

print(f"Testing endpoint {endpoint_name}...")
response = deploy_client.predict(endpoint=f'/serving-endpoints/{endpoint_name}', inputs=input_example)

print("Test response:")
print(response['output'])
